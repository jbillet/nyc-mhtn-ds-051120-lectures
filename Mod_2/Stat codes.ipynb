{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample variance\n",
    "np.var()\n",
    "def sample_variance(sample_men):\n",
    "    sample_mean = np.mean(sample_men)\n",
    "    return np.sum((sample_men - sample_mean) **2)/ (len(sample_men) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled variance ttest\n",
    "def pooled_variance(s_men, s_women):\n",
    "    n_1, n_2 = len(s_men), len(s_women)\n",
    "    var_1, var_2 = sample_variance(s_men), sample_variance(s_women)\n",
    "    return ((n_1-1) * var_1 + (n_2-1)* var_2)/((n_1 + n_2)-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the zscore\n",
    "stats.norm.ppf()\n",
    "\n",
    "#find the pvalue\n",
    "stats.norm.cdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence interval zscore\n",
    "def confidence_zscore(pop_mean, sigma, alpha1):\n",
    "    return stats.norm.interval(alpha = alpha1, loc = pop_mean, scale = sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence interval tscore\n",
    "def confidence_zscore(pop_mean, sigma, alpha1, dof):\n",
    "    return stats.t.interval(alpha = alpha1, loc = pop_mean, df = dof, scale = sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample is the specific column, can be replaced with the number of observations and delete the len()\n",
    "# One tail one sample lower tail: tscore\n",
    "def lower_one_sample_ttest(sample, sample_mean, pop_mean, sigma1, alpha1):\n",
    "    mu = pop_mean\n",
    "    x_bar = sample_mean\n",
    "    sigma = sigma1\n",
    "    alpha = alpha1\n",
    "    df = len(sample) - 1\n",
    "    t_crit = stats.t.ppf(alpha, df=df)\n",
    "    results = stats.ttest_1samp(a= sample, popmean= mu)\n",
    "    if results[0] > t_crit:\n",
    "        print (\"With the current information, we fail to reject the Null hypothesis with t-stat =\",\n",
    "                round(results[0], 2), \",  critical t-value =\",  t_crit, \"and p-value =\", np.round((results[1]), 10))\n",
    "    else:\n",
    "        print (\"We reject the Null hypothesis. Results are statistically significant with t-stat =\",\n",
    "                round(results[0], 2), \"critical t-value\",  t_crit, \"and p-value =\", np.round((results[1]), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One tail one sample upper tail: tscore\n",
    "def upper_one_sample_ttest(sample, sample_mean, pop_mean, sigma1, alpha1):\n",
    "    mu = pop_mean\n",
    "    x_bar = sample_mean\n",
    "    sigma = sigma1\n",
    "    alpha = alpha1\n",
    "    df = len(sample) - 1\n",
    "    t_crit = stats.t.ppf(1-alpha, df=df)\n",
    "    results = stats.ttest_1samp(a= sample, popmean= mu)\n",
    "    if results[0] >t_crit:\n",
    "        print (\"With the current information, we fail to reject the Null hypothesis with t-stat =\",\n",
    "                round(results[0], 2), \",  critical t-value =\", t_crit, \"and p-value =\", np.round((results[1]), 10))\n",
    "    else:\n",
    "        print (\"We reject the Null hypothesis. Results are statistically significant with t-stat =\",\n",
    "                round(results[0], 2), \"between critical t-values \", t_crit, \"and p-value =\", np.round((results[1]), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two tail one sample: tscore\n",
    "def two_tail_one_sample_ttest(sample, sample_mean, pop_mean, sigma1, alpha1):\n",
    "    mu = pop_mean\n",
    "    x_bar = sample_mean\n",
    "    sigma = sigma1\n",
    "    alpha = alpha1 /2\n",
    "    df = len(sample) - 1\n",
    "    t_crit = stats.t.ppf(1-alpha, df=df)\n",
    "    t_crit2 = (-1* t_crit)\n",
    "    results = stats.ttest_1samp(a= sample, popmean= mu)\n",
    "    if t_crit2 < results[0] <t_crit:\n",
    "        print (\"With the current information, we fail to reject the Null hypothesis with t-stat =\",\n",
    "                round(results[0], 2), \", between critical t-values =\", t_crit2, ' &', t_crit, \"and p-value =\", np.round((results[1]), 10))\n",
    "    else:\n",
    "        print (\"We reject the Null hypothesis. Results are statistically significant with t-stat =\",\n",
    "                round(results[0], 2), \"between critical t-values =\", t_crit2, ' &', t_crit, \"and p-value =\", np.round((results[1]), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = number of obsevations\n",
    "# One tail one sample lower tail: zscore\n",
    "def lower_one_sample_ztest(sample, sample_mean, pop_mean, sigma1, alpha1):\n",
    "    mu = pop_mean\n",
    "    x_bar = sample_mean\n",
    "    sigma = sigma1\n",
    "    alpha = alpha1\n",
    "    df = (sample) - 1\n",
    "    z_crit = stats.norm.ppf(alpha)\n",
    "    results = (xbar- pop_mean)/(sigma1/np.sqrt((sample)))\n",
    "    if results >z_crit:\n",
    "        print (\"With the current information, we fail to reject the Null hypothesis with z-stat =\",\n",
    "                round(results, 2), \", critical z-value =\", z_crit)\n",
    "    else:\n",
    "        print (\"We reject the Null hypothesis. Results are statistically significant with z-stat =\",\n",
    "                round(results, 2), \" critical z-value =\", z_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One tail one sample upper tail: zscore\n",
    "def upper_one_sample_ztest(sample, sample_mean, pop_mean, sigma1, alpha1):\n",
    "    mu = pop_mean\n",
    "    x_bar = sample_mean\n",
    "    sigma = sigma1\n",
    "    alpha = alpha1\n",
    "    df = (sample) - 1\n",
    "    z_crit = stats.norm.ppf(1-alpha)\n",
    "    results = (xbar- pop_mean)/(sigma1/np.sqrt((sample)))\n",
    "    if results <z_crit:\n",
    "        print (\"With the current information, we fail to reject the Null hypothesis with z-stat =\",\n",
    "                round(results, 2), \", critical z-value = \", z_crit)\n",
    "    else:\n",
    "        print (\"We reject the Null hypothesis. Results are statistically significant with z-stat =\",\n",
    "                round(results, 2), \" critical z-value =\", z_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two tail one sample: zscore\n",
    "def two_tail_one_sample_ztest(sample, sample_mean, pop_mean, sigma1, alpha1):\n",
    "    mu = pop_mean\n",
    "    x_bar = sample_mean\n",
    "    sigma = sigma1\n",
    "    alpha = alpha1 /2\n",
    "    df = len(sample) - 1\n",
    "    z_crit = stats.norm.ppf(1-alpha)\n",
    "    z_crit2 = (-1* t_crit)\n",
    "    results = (xbar- pop_mean)/(sigma1/np.sqrt(len(sample)))\n",
    "    if z_crit2 < results <z_crit:\n",
    "        print (\"With the current information, we fail to reject the Null hypothesis with z-stat =\",\n",
    "                round(results, 2), \", between critical z-values \", z_crit2, ' &', z_crit)\n",
    "    else:\n",
    "        print (\"We reject the Null hypothesis. Results are statistically significant with z-stat =\",\n",
    "                round(results, 2), \"between critical z-values \", z_crit2, ' &', z_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One tail two sample lower tail:  zscore\n",
    "\n",
    "\n",
    "#One tail two sample upper tail: zscore\n",
    "\n",
    "#Two tail two sample upper tail: zscore\n",
    "\n",
    "\n",
    "#One tail two sample lower tail:  tscore\n",
    "def twosample_tstatistic(expr, ctrl):\n",
    "    exp_mean, ctrl_mean = np.mean(expr), np.mean(ctrl)\n",
    "    pool_var = pooled_variance(expr, ctrl)\n",
    "    n_e, n_c = len(expr), len(ctrl)\n",
    "    num = exp_mean - ctrl_mean\n",
    "    denom = np.sqrt(pool_var * ((1/n_e)+(1/n_c)))\n",
    "    return num / denom\n",
    "\n",
    "#One tail two sample upper tail: tscore\n",
    "\n",
    "#Two tail two sample upper tail: tscore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes Theorem\n",
    "def bayes(P_a, P_b, P_b_given_a):\n",
    "    P_a_given_b = (P_b_given_a * P_a)/P_b\n",
    "    return P_a_given_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooled_variance = when the sample variances are similar to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Interval\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "mean_confidence_interval(df['PHYSHLTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Interval from morning code challenge\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def confidence(data, confidence):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2, n-1)\n",
    "    return [round(m-h,4), round(m+h,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Interval \n",
    "\n",
    "# Sam is sample\n",
    "# P is confidence\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem, t\n",
    "def confidence(sam, p):\n",
    "    mean, std_err, n = np.mean(sam), sem(sam), len(sam)\n",
    "    interval = t.ppf((1 + p) / 2, n - 1)\n",
    "    interval *= std_err\n",
    "    mean *= 10000\n",
    "    interval *= 10000\n",
    "    return [int(round(mean - interval))/10000, int(round(mean + interval))/10000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
